"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[951],{5721:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"modules/module-3-ai-brain/isaac-sim","title":"Isaac Sim: Photorealistic Simulation + Synthetic Data","description":"Introduction","source":"@site/docs/modules/module-3-ai-brain/01-isaac-sim.mdx","sourceDirName":"modules/module-3-ai-brain","slug":"/modules/module-3-ai-brain/isaac-sim","permalink":"/docs/modules/module-3-ai-brain/isaac-sim","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/modules/module-3-ai-brain/01-isaac-sim.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_label":"Isaac Sim: Photorealistic Simulation + Synthetic Data","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Module 3: AI-Robot Brain (NVIDIA Isaac\u2122)","permalink":"/docs/modules/module-3-ai-brain/"},"next":{"title":"Isaac ROS Pipelines: VSLAM, Navigation","permalink":"/docs/modules/module-3-ai-brain/isaac-ros-pipelines"}}');var t=i(4848),s=i(8453);const r={sidebar_label:"Isaac Sim: Photorealistic Simulation + Synthetic Data",sidebar_position:1},o="Isaac Sim: Photorealistic Simulation + Synthetic Data",l={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Isaac Sim Architecture",id:"isaac-sim-architecture",level:2},{value:"Installing and Setting Up Isaac Sim",id:"installing-and-setting-up-isaac-sim",level:2},{value:"Basic Setup",id:"basic-setup",level:3},{value:"USD (Universal Scene Description) in Isaac Sim",id:"usd-universal-scene-description-in-isaac-sim",level:2},{value:"Creating Photorealistic Environments",id:"creating-photorealistic-environments",level:2},{value:"Environment Setup",id:"environment-setup",level:3},{value:"Lighting and Materials",id:"lighting-and-materials",level:3},{value:"Humanoid Robot Integration",id:"humanoid-robot-integration",level:2},{value:"Loading Humanoid Robots",id:"loading-humanoid-robots",level:3},{value:"Robot Control in Isaac Sim",id:"robot-control-in-isaac-sim",level:3},{value:"Synthetic Data Generation",id:"synthetic-data-generation",level:2},{value:"RGB Camera Data",id:"rgb-camera-data",level:3},{value:"Depth and Semantic Segmentation",id:"depth-and-semantic-segmentation",level:3},{value:"Labeled Training Data Pipeline",id:"labeled-training-data-pipeline",level:3},{value:"Isaac Sim Extensions",id:"isaac-sim-extensions",level:2},{value:"ROS 2 Bridge",id:"ros-2-bridge",level:3},{value:"Isaac ROS Extensions",id:"isaac-ros-extensions",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Level of Detail (LOD)",id:"level-of-detail-lod",level:3},{value:"Rendering Optimization",id:"rendering-optimization",level:3},{value:"Best Practices for Humanoid Robotics",id:"best-practices-for-humanoid-robotics",level:2},{value:"Environment Design",id:"environment-design",level:3},{value:"Data Generation",id:"data-generation",level:3},{value:"Simulation Fidelity",id:"simulation-fidelity",level:3},{value:"Troubleshooting Common Issues",id:"troubleshooting-common-issues",level:2},{value:"Performance Issues",id:"performance-issues",level:3},{value:"Physics Issues",id:"physics-issues",level:3},{value:"Rendering Issues",id:"rendering-issues",level:3},{value:"RAG Summary",id:"rag-summary",level:2},{value:"Knowledge Check",id:"knowledge-check",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"isaac-sim-photorealistic-simulation--synthetic-data",children:"Isaac Sim: Photorealistic Simulation + Synthetic Data"})}),"\n",(0,t.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsx)(n.p,{children:"NVIDIA Isaac Sim is a powerful robotics simulation environment built on the Omniverse platform. It provides photorealistic rendering capabilities and synthetic data generation tools essential for training AI models for humanoid robots. This chapter explores Isaac Sim's capabilities for creating realistic simulation environments and generating training data."}),"\n",(0,t.jsx)(n.h2,{id:"isaac-sim-architecture",children:"Isaac Sim Architecture"}),"\n",(0,t.jsx)(n.p,{children:"Isaac Sim leverages NVIDIA's Omniverse platform to provide:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"PhysX Physics Engine"}),": Realistic physics simulation"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"RTX Ray Tracing"}),": Photorealistic rendering"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"USD Scene Format"}),": Universal Scene Description for complex scenes"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ROS 2 Bridge"}),": Seamless integration with ROS 2 ecosystem"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Synthetic Data Generation"}),": Tools for creating labeled training data"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"installing-and-setting-up-isaac-sim",children:"Installing and Setting Up Isaac Sim"}),"\n",(0,t.jsx)(n.p,{children:"Isaac Sim can be deployed in multiple ways:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Docker Container"}),": Pre-built containers for easy deployment"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Isaac Sim Omniverse Extension"}),": Integrated with Omniverse Create/View"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Standalone Application"}),": Full application with all features"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"basic-setup",children:"Basic Setup"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'# Pull the Isaac Sim Docker image\ndocker pull nvcr.io/nvidia/isaac-sim:latest\n\n# Run Isaac Sim with GPU acceleration\ndocker run --gpus all -it --rm \\\n  --network=host \\\n  --env "ACCEPT_EULA=Y" \\\n  --volume $(pwd):/workspace \\\n  --volume /tmp/.X11-unix:/tmp/.X11-unix:rw \\\n  --env "DISPLAY=$DISPLAY" \\\n  --env "QT_X11_NO_MITSHM=1" \\\n  --privileged \\\n  nvcr.io/nvidia/isaac-sim:latest\n'})}),"\n",(0,t.jsx)(n.h2,{id:"usd-universal-scene-description-in-isaac-sim",children:"USD (Universal Scene Description) in Isaac Sim"}),"\n",(0,t.jsx)(n.p,{children:"USD is the core format for scenes in Isaac Sim:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Example of creating a USD stage in Isaac Sim\nimport omni\nfrom pxr import Usd, UsdGeom, Gf, Sdf\n\n# Create a new USD stage\nstage = Usd.Stage.CreateNew("humanoid_scene.usd")\n\n# Create a root prim\nworld_prim = stage.DefinePrim("/World", "Xform")\n\n# Add a humanoid robot\nrobot_prim = world_prim.GetChildren()[0] if world_prim.GetChildren() else stage.DefinePrim("/World/Robot", "Xform")\n\n# Save the stage\nstage.GetRootLayer().Save()\n'})}),"\n",(0,t.jsx)(n.h2,{id:"creating-photorealistic-environments",children:"Creating Photorealistic Environments"}),"\n",(0,t.jsx)(n.h3,{id:"environment-setup",children:"Environment Setup"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Example of creating a photorealistic environment\nimport omni\nfrom omni.isaac.core import World\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\n\n# Create a world instance\nworld = World(stage_units_in_meters=1.0)\n\n# Add a photorealistic environment\nassets_root_path = get_assets_root_path()\nif assets_root_path is None:\n    print("Could not find Isaac Sim assets. Please enable Isaac Sim Nucleus.")\nelse:\n    # Add a warehouse environment\n    env_path = assets_root_path + "/Isaac/Environments/Simple_Warehouse/warehouse.usd"\n    add_reference_to_stage(usd_path=env_path, prim_path="/World/warehouse")\n'})}),"\n",(0,t.jsx)(n.h3,{id:"lighting-and-materials",children:"Lighting and Materials"}),"\n",(0,t.jsx)(n.p,{children:"Isaac Sim supports advanced lighting and materials:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Example of setting up realistic lighting\nfrom omni.isaac.core.utils.prims import create_prim\nfrom omni.isaac.core.utils.stage import get_current_stage\nfrom pxr import Gf\n\n# Create a dome light for environment lighting\ncreate_prim(\n    prim_path="/World/DomeLight",\n    prim_type="DomeLight",\n    position=Gf.Vec3f(0, 0, 0),\n    attributes={"color": Gf.Vec3f(0.5, 0.5, 0.5), "intensity": 3000}\n)\n\n# Create a distant light for directional lighting\ncreate_prim(\n    prim_path="/World/DistantLight",\n    prim_type="DistantLight",\n    position=Gf.Vec3f(0, 0, 50),\n    orientation=Gf.Quatf(0.707, 0.707, 0, 0),  # Pointing downward\n    attributes={"color": Gf.Vec3f(0.9, 0.9, 0.9), "intensity": 1000}\n)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"humanoid-robot-integration",children:"Humanoid Robot Integration"}),"\n",(0,t.jsx)(n.h3,{id:"loading-humanoid-robots",children:"Loading Humanoid Robots"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Example of loading a humanoid robot in Isaac Sim\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.core import World\n\n# Add a humanoid robot to the scene\nassets_root_path = get_assets_root_path()\nif assets_root_path:\n    robot_path = assets_root_path + "/Isaac/Robots/Franka/franka_alt_fingers.usd"\n    # Note: For humanoid robots, you would use a humanoid-specific model\n    add_reference_to_stage(\n        usd_path=robot_path,\n        prim_path="/World/Robot"\n    )\n'})}),"\n",(0,t.jsx)(n.h3,{id:"robot-control-in-isaac-sim",children:"Robot Control in Isaac Sim"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Example of controlling a robot in Isaac Sim\nimport numpy as np\nfrom omni.isaac.core import World\nfrom omni.isaac.core.articulations import Articulation\n\n# Get the robot from the world\nworld = World()\nrobot = world.scene.get_object("Robot")\n\n# Set joint positions\nif isinstance(robot, Articulation):\n    joint_positions = np.array([0.0, -1.0, 0.0, -2.0, 0.0, 1.5, 0.0])  # Example joint positions\n    robot.set_joint_positions(joint_positions)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"synthetic-data-generation",children:"Synthetic Data Generation"}),"\n",(0,t.jsx)(n.h3,{id:"rgb-camera-data",children:"RGB Camera Data"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Example of capturing RGB images for synthetic data\nfrom omni.isaac.sensor import Camera\nfrom omni.isaac.core.utils.prims import get_prim_at_path\nimport numpy as np\n\n# Create a camera\ncamera = Camera(\n    prim_path="/World/Camera",\n    position=np.array([1.0, 1.0, 1.0]),\n    orientation=np.array([0.5, -0.5, -0.5, 0.5])\n)\n\n# Initialize the world and camera\nworld = World()\nworld.reset()\n\n# Capture RGB image\nrgb_data = camera.get_rgb()\nprint(f"RGB image shape: {rgb_data.shape}")\n'})}),"\n",(0,t.jsx)(n.h3,{id:"depth-and-semantic-segmentation",children:"Depth and Semantic Segmentation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Example of capturing depth and semantic segmentation data\nimport omni\nfrom omni.isaac.sensor import Camera\nimport numpy as np\n\n# Create a camera with depth and segmentation capabilities\ncamera = Camera(\n    prim_path="/World/Camera",\n    position=np.array([1.0, 1.0, 1.0]),\n    orientation=np.array([0.5, -0.5, -0.5, 0.5])\n)\n\n# Initialize and reset the world\nworld = World()\nworld.reset()\n\n# Capture depth data\ndepth_data = camera.get_depth()\n\n# Capture semantic segmentation data\nsemantic_data = camera.get_semantic_segmentation()\n\nprint(f"Depth data shape: {depth_data.shape}")\nprint(f"Semantic data shape: {semantic_data.shape}")\n'})}),"\n",(0,t.jsx)(n.h3,{id:"labeled-training-data-pipeline",children:"Labeled Training Data Pipeline"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Example synthetic data generation pipeline\nimport os\nimport numpy as np\nfrom PIL import Image\nimport json\n\nclass SyntheticDataGenerator:\n    def __init__(self, output_dir="synthetic_data"):\n        self.output_dir = output_dir\n        self.image_count = 0\n\n        # Create output directories\n        os.makedirs(os.path.join(output_dir, "images"), exist_ok=True)\n        os.makedirs(os.path.join(output_dir, "labels"), exist_ok=True)\n\n    def capture_and_save_data(self, camera, semantic_labels):\n        """Capture RGB, depth, and semantic data"""\n        # Capture data\n        rgb_image = camera.get_rgb()\n        depth_data = camera.get_depth()\n        semantic_data = camera.get_semantic_segmentation()\n\n        # Save RGB image\n        rgb_pil = Image.fromarray(rgb_image)\n        image_filename = f"image_{self.image_count:06d}.png"\n        rgb_pil.save(os.path.join(self.output_dir, "images", image_filename))\n\n        # Save semantic labels\n        semantic_pil = Image.fromarray(semantic_data.astype(np.uint8))\n        semantic_filename = f"semantic_{self.image_count:06d}.png"\n        semantic_pil.save(os.path.join(self.output_dir, "labels", semantic_filename))\n\n        # Save metadata\n        metadata = {\n            "image_filename": image_filename,\n            "semantic_filename": semantic_filename,\n            "depth_stats": {\n                "min": float(np.min(depth_data)),\n                "max": float(np.max(depth_data)),\n                "mean": float(np.mean(depth_data))\n            },\n            "timestamp": self.image_count\n        }\n\n        meta_filename = f"metadata_{self.image_count:06d}.json"\n        with open(os.path.join(self.output_dir, meta_filename), \'w\') as f:\n            json.dump(metadata, f)\n\n        self.image_count += 1\n        print(f"Saved synthetic data sample {self.image_count}")\n\n    def generate_dataset(self, camera, num_samples=1000):\n        """Generate a complete synthetic dataset"""\n        for i in range(num_samples):\n            # Move camera or objects to create variety\n            # This would involve robot movement or environment changes\n            self.capture_and_save_data(camera, {})\n'})}),"\n",(0,t.jsx)(n.h2,{id:"isaac-sim-extensions",children:"Isaac Sim Extensions"}),"\n",(0,t.jsx)(n.h3,{id:"ros-2-bridge",children:"ROS 2 Bridge"}),"\n",(0,t.jsx)(n.p,{children:"Isaac Sim includes a ROS 2 bridge for integration:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Example of using the ROS 2 bridge in Isaac Sim\nimport omni\nfrom omni.isaac.core import World\nfrom omni.isaac.ros_bridge import ROSBridge\n\n# Initialize ROS bridge\nros_bridge = ROSBridge()\nworld = World()\n\n# The bridge automatically handles ROS 2 communication\n# when Isaac Sim is built with ROS 2 support\n"})}),"\n",(0,t.jsx)(n.h3,{id:"isaac-ros-extensions",children:"Isaac ROS Extensions"}),"\n",(0,t.jsx)(n.p,{children:"Isaac Sim integrates with Isaac ROS extensions for perception:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Example of using Isaac ROS extensions\nfrom omni.isaac.core import World\nimport omni.isaac.core.utils.prims as prims\n\n# Set up Isaac ROS nodes in the simulation\ndef setup_isaac_ros_nodes():\n    # Create Isaac ROS nodes as USD prims\n    # These would connect to actual ROS 2 topics\n    pass\n\nworld = World()\nsetup_isaac_ros_nodes()\n"})}),"\n",(0,t.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,t.jsx)(n.h3,{id:"level-of-detail-lod",children:"Level of Detail (LOD)"}),"\n",(0,t.jsx)(n.p,{children:"Isaac Sim supports various optimization techniques:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Example of optimizing simulation performance\nfrom omni.isaac.core import World\n\n# Reduce physics update rate for better performance\nworld = World(stage_units_in_meters=1.0)\nworld.physics_sim_view.set_simulation_dt(1.0/60.0)  # 60 Hz physics update\n"})}),"\n",(0,t.jsx)(n.h3,{id:"rendering-optimization",children:"Rendering Optimization"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Example of rendering optimization\nimport omni\nfrom omni import kit\n\n# Reduce rendering quality for faster simulation\nconfig = {\n    "rtx-hydra:renderer:renderQualityOverride": 0,  # Low quality\n    "rtx-hydra:renderer:raytracing": False,  # Disable raytracing\n    "rtx-hydra:renderer:ambientOcclusion": False\n}\n\nfor key, value in config.items():\n    omni.kit.commands.execute("ChangeSetting", path=key, value=value)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"best-practices-for-humanoid-robotics",children:"Best Practices for Humanoid Robotics"}),"\n",(0,t.jsx)(n.h3,{id:"environment-design",children:"Environment Design"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Realistic Textures"}),": Use high-quality textures for photorealistic rendering"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Dynamic Lighting"}),": Include variable lighting conditions"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Diverse Scenarios"}),": Create various environments for robust training"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Physics Accuracy"}),": Ensure realistic physics parameters"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"data-generation",children:"Data Generation"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Variety"}),": Generate data with different lighting, viewpoints, and scenarios"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Quality"}),": Ensure high-resolution and accurate annotations"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Volume"}),": Generate sufficient data for training deep learning models"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Validation"}),": Verify data quality and consistency"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"simulation-fidelity",children:"Simulation Fidelity"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Domain Randomization"}),": Vary environment parameters for robustness"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sensor Noise"}),": Include realistic sensor noise models"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Actuator Dynamics"}),": Model real actuator behavior"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Timing"}),": Match real-world timing characteristics"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"troubleshooting-common-issues",children:"Troubleshooting Common Issues"}),"\n",(0,t.jsx)(n.h3,{id:"performance-issues",children:"Performance Issues"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Reduce scene complexity"}),"\n",(0,t.jsx)(n.li,{children:"Lower rendering quality settings"}),"\n",(0,t.jsx)(n.li,{children:"Optimize USD scene structure"}),"\n",(0,t.jsx)(n.li,{children:"Use appropriate hardware (RTX GPU recommended)"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"physics-issues",children:"Physics Issues"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Verify mass and inertia properties"}),"\n",(0,t.jsx)(n.li,{children:"Check joint limits and dynamics"}),"\n",(0,t.jsx)(n.li,{children:"Adjust solver parameters"}),"\n",(0,t.jsx)(n.li,{children:"Validate collision geometries"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"rendering-issues",children:"Rendering Issues"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Check material assignments"}),"\n",(0,t.jsx)(n.li,{children:"Verify lighting setup"}),"\n",(0,t.jsx)(n.li,{children:"Validate camera parameters"}),"\n",(0,t.jsx)(n.li,{children:"Ensure proper USD stage structure"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"rag-summary",children:"RAG Summary"}),"\n",(0,t.jsx)(n.p,{children:"Isaac Sim provides photorealistic simulation and synthetic data generation for humanoid robotics using NVIDIA's Omniverse platform. It features RTX ray tracing, PhysX physics, USD scene format, and ROS 2 integration. The platform enables generation of high-quality training data with RGB, depth, and semantic segmentation for AI model training."}),"\n",(0,t.jsx)(n.h2,{id:"knowledge-check",children:"Knowledge Check"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"What is the architecture of Isaac Sim and its key components?"}),"\n",(0,t.jsx)(n.li,{children:"How do you set up a photorealistic environment in Isaac Sim?"}),"\n",(0,t.jsx)(n.li,{children:"What types of synthetic data can be generated with Isaac Sim?"}),"\n",(0,t.jsx)(n.li,{children:"How does Isaac Sim integrate with ROS 2?"}),"\n",(0,t.jsx)(n.li,{children:"What are the best practices for synthetic data generation?"}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r});var a=i(6540);const t={},s=a.createContext(t);function r(e){const n=a.useContext(s);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}}}]);