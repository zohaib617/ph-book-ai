"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[101],{3833:(n,e,o)=>{o.r(e),o.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>_,frontMatter:()=>s,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"modules/module-3-ai-brain/nav2-bipedal","title":"Nav2 for Bipedal Humanoid Movement","description":"Introduction","source":"@site/docs/modules/module-3-ai-brain/03-nav2-bipedal.mdx","sourceDirName":"modules/module-3-ai-brain","slug":"/modules/module-3-ai-brain/nav2-bipedal","permalink":"/docs/modules/module-3-ai-brain/nav2-bipedal","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/modules/module-3-ai-brain/03-nav2-bipedal.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_label":"Nav2 for Bipedal Humanoid Movement","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Isaac ROS Pipelines: VSLAM, Navigation","permalink":"/docs/modules/module-3-ai-brain/isaac-ros-pipelines"},"next":{"title":"Module 4: Vision-Language-Action (VLA)","permalink":"/docs/modules/module-4-vla/"}}');var i=o(4848),t=o(8453);const s={sidebar_label:"Nav2 for Bipedal Humanoid Movement",sidebar_position:3},r="Nav2 for Bipedal Humanoid Movement",l={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Nav2 Architecture Overview",id:"nav2-architecture-overview",level:2},{value:"Nav2 Core Components",id:"nav2-core-components",level:3},{value:"Bipedal Navigation Challenges",id:"bipedal-navigation-challenges",level:2},{value:"Balance and Stability",id:"balance-and-stability",level:3},{value:"Motion Constraints",id:"motion-constraints",level:3},{value:"Nav2 Configuration for Humanoid Robots",id:"nav2-configuration-for-humanoid-robots",level:2},{value:"Costmap Configuration",id:"costmap-configuration",level:3},{value:"Global Planner Configuration",id:"global-planner-configuration",level:3},{value:"Footstep Planning for Bipedal Navigation",id:"footstep-planning-for-bipedal-navigation",level:2},{value:"Footstep Planner Integration",id:"footstep-planner-integration",level:3},{value:"Balance Control Integration",id:"balance-control-integration",level:2},{value:"Center of Mass Management",id:"center-of-mass-management",level:3},{value:"Navigation Recovery Behaviors for Humanoids",id:"navigation-recovery-behaviors-for-humanoids",level:2},{value:"Specialized Recovery Behaviors",id:"specialized-recovery-behaviors",level:3},{value:"Simulation and Testing",id:"simulation-and-testing",level:2},{value:"Gazebo Integration for Humanoid Nav2",id:"gazebo-integration-for-humanoid-nav2",level:3},{value:"Testing Navigation Scenarios",id:"testing-navigation-scenarios",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Computational Efficiency for Humanoid Navigation",id:"computational-efficiency-for-humanoid-navigation",level:3},{value:"Best Practices for Humanoid Navigation",id:"best-practices-for-humanoid-navigation",level:2},{value:"Safety Considerations",id:"safety-considerations",level:3},{value:"Performance Optimization",id:"performance-optimization-1",level:3},{value:"Testing and Validation",id:"testing-and-validation",level:3},{value:"Troubleshooting Common Issues",id:"troubleshooting-common-issues",level:2},{value:"Navigation Failures",id:"navigation-failures",level:3},{value:"Balance Problems",id:"balance-problems",level:3},{value:"Performance Issues",id:"performance-issues",level:3},{value:"RAG Summary",id:"rag-summary",level:2},{value:"Knowledge Check",id:"knowledge-check",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"nav2-for-bipedal-humanoid-movement",children:"Nav2 for Bipedal Humanoid Movement"})}),"\n",(0,i.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,i.jsx)(e.p,{children:"Navigation2 (Nav2) is ROS 2's state-of-the-art navigation framework, designed for autonomous navigation of mobile robots. This chapter focuses on adapting Nav2 for bipedal humanoid robots, addressing the unique challenges of legged locomotion compared to wheeled robots. We'll explore how to configure and customize Nav2 for stable and efficient bipedal navigation."}),"\n",(0,i.jsx)(e.h2,{id:"nav2-architecture-overview",children:"Nav2 Architecture Overview"}),"\n",(0,i.jsx)(e.p,{children:"Nav2 follows a behavior tree architecture with several key components:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Navigation Server"}),": Central coordinator for navigation tasks"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Planners"}),": Global and local path planning algorithms"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Controllers"}),": Trajectory generation and execution"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Recovery Behaviors"}),": Actions for handling navigation failures"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Sensors Interface"}),": Integration with perception systems"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"nav2-core-components",children:"Nav2 Core Components"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-yaml",children:'# Example Nav2 configuration for humanoid robot\namcl:\n  ros__parameters:\n    use_sim_time: True\n    alpha1: 0.2\n    alpha2: 0.2\n    alpha3: 0.2\n    alpha4: 0.2\n    alpha5: 0.2\n    base_frame_id: "base_link"\n    beam_skip_distance: 0.5\n    beam_skip_error_threshold: 0.9\n    beam_skip_threshold: 0.3\n    do_beamskip: false\n    global_frame_id: "map"\n    lambda_short: 0.1\n    laser_likelihood_max_dist: 2.0\n    laser_max_range: 100.0\n    laser_min_range: -1.0\n    laser_model_type: "likelihood_field"\n    max_beams: 60\n    max_particles: 2000\n    min_particles: 500\n    odom_frame_id: "odom"\n    pf_err: 0.05\n    pf_z: 0.99\n    recovery_alpha_fast: 0.0\n    recovery_alpha_slow: 0.0\n    resample_interval: 1\n    robot_model_type: "omnidirectional"  # Important for humanoid\n    save_pose_rate: 0.5\n    sigma_hit: 0.2\n    tf_broadcast: true\n    transform_tolerance: 1.0\n    update_min_a: 0.2\n    update_min_d: 0.25\n    z_hit: 0.5\n    z_max: 0.05\n    z_rand: 0.05\n    z_short: 0.05\n'})}),"\n",(0,i.jsx)(e.h2,{id:"bipedal-navigation-challenges",children:"Bipedal Navigation Challenges"}),"\n",(0,i.jsx)(e.h3,{id:"balance-and-stability",children:"Balance and Stability"}),"\n",(0,i.jsx)(e.p,{children:"Bipedal robots face unique challenges compared to wheeled robots:"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Dynamic Balance"}),": Maintaining balance during movement"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Foot Placement"}),": Precise footstep planning"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Center of Mass"}),": Managing CoM during navigation"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Ground Contact"}),": Ensuring stable foot-ground contact"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"motion-constraints",children:"Motion Constraints"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# Example of bipedal motion constraints in Nav2\nclass BipedalMotionConstraints:\n    def __init__(self):\n        self.max_step_length = 0.3  # meters\n        self.max_step_width = 0.2  # meters\n        self.max_step_height = 0.1  # meters (for step climbing)\n        self.min_turn_radius = 0.5  # meters (turning constraints)\n        self.max_linear_velocity = 0.5  # m/s\n        self.max_angular_velocity = 0.3  # rad/s\n        self.step_duration = 1.0  # seconds per step\n        self.zmp_margin = 0.05  # Zero Moment Point safety margin\n\n    def is_trajectory_valid(self, trajectory):\n        """Check if a trajectory is valid for bipedal locomotion"""\n        for point in trajectory:\n            # Check step length constraints\n            if point.step_length > self.max_step_length:\n                return False\n\n            # Check velocity constraints\n            if point.linear_velocity > self.max_linear_velocity:\n                return False\n\n            if point.angular_velocity > self.max_angular_velocity:\n                return False\n\n        return True\n'})}),"\n",(0,i.jsx)(e.h2,{id:"nav2-configuration-for-humanoid-robots",children:"Nav2 Configuration for Humanoid Robots"}),"\n",(0,i.jsx)(e.h3,{id:"costmap-configuration",children:"Costmap Configuration"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-yaml",children:'# Costmap configuration for bipedal navigation\nglobal_costmap:\n  global_costmap:\n    ros__parameters:\n      update_frequency: 5.0\n      publish_frequency: 2.0\n      global_frame: map\n      robot_base_frame: base_link\n      use_dijkstra: true\n      use_grid_path: false\n      allow_unknown: true\n      track_unknown_space: true\n      footprint: [[-0.3, -0.2], [-0.3, 0.2], [0.3, 0.2], [0.3, -0.2]]\n      footprint_padding: 0.05\n      resolution: 0.05  # Higher resolution for precise foot placement\n      robot_radius: 0.3\n      plugins: ["static_layer", "obstacle_layer", "inflation_layer"]\n      obstacle_layer:\n        enabled: True\n        observation_sources: scan\n        scan:\n          topic: /scan\n          max_obstacle_height: 2.0\n          clearing: True\n          marking: True\n          data_type: LaserScan\n      static_layer:\n        map_topic: map\n        enabled: true\n        subscribe_to_updates: true\n      inflation_layer:\n        enabled: true\n        cost_scaling_factor: 3.0  # Higher for humanoid safety\n        inflation_radius: 0.55    # Larger for bipedal stability\n\nlocal_costmap:\n  local_costmap:\n    ros__parameters:\n      update_frequency: 10.0\n      publish_frequency: 5.0\n      global_frame: odom\n      robot_base_frame: base_link\n      rolling_window: true\n      width: 5  # Smaller for humanoid agility\n      height: 5\n      resolution: 0.05\n      robot_radius: 0.3\n      plugins: ["obstacle_layer", "voxel_layer", "inflation_layer"]\n      obstacle_layer:\n        enabled: True\n        observation_sources: scan\n        scan:\n          topic: /scan\n          max_obstacle_height: 2.0\n          clearing: True\n          marking: True\n          data_type: LaserScan\n      voxel_layer:\n        enabled: True\n        publish_voxel_map: True\n        origin_z: 0.0\n        z_resolution: 0.2\n        z_voxels: 10\n        max_obstacle_height: 2.0\n        mark_threshold: 0\n        observation_sources: scan\n      inflation_layer:\n        enabled: true\n        cost_scaling_factor: 5.0  # Higher for local safety\n        inflation_radius: 0.6\n'})}),"\n",(0,i.jsx)(e.h3,{id:"global-planner-configuration",children:"Global Planner Configuration"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-yaml",children:'# Global planner for humanoid navigation\nbt_navigator:\n  ros__parameters:\n    use_sim_time: True\n    global_frame: map\n    robot_base_frame: base_link\n    odom_topic: /odom\n    default_bt_xml_filename: "navigate_w_replanning_and_recovery.xml"\n    plugin_lib_names:\n    - nav2_compute_path_to_pose_action_bt_node\n    - nav2_follow_path_action_bt_node\n    - nav2_back_up_action_bt_node\n    - nav2_spin_action_bt_node\n    - nav2_wait_action_bt_node\n    - nav2_clear_costmap_service_bt_node\n    - nav2_is_stuck_condition_bt_node\n    - nav2_goal_reached_condition_bt_node\n    - nav2_goal_updated_condition_bt_node\n    - nav2_initial_pose_received_condition_bt_node\n    - nav2_reinitialize_global_localization_service_bt_node\n    - nav2_rate_controller_bt_node\n    - nav2_distance_controller_bt_node\n    - nav2_speed_controller_bt_node\n    - nav2_truncate_path_action_bt_node\n    - nav2_goal_updater_node_bt_node\n    - nav2_recovery_node_bt_node\n    - nav2_pipeline_sequence_bt_node\n    - nav2_round_robin_node_bt_node\n    - nav2_transform_available_condition_bt_node\n    - nav2_time_expired_condition_bt_node\n    - nav2_path_expiring_timer_condition\n    - nav2_distance_traveled_condition_bt_node\n    - nav2_single_trigger_bt_node\n    - nav2_is_path_valid_condition_bt_node\n    - nav2_compute_path_through_poses_action_bt_node\n    - nav2_compute_path_to_pose_action_bt_node\n    - nav2_smooth_path_action_bt_node\n'})}),"\n",(0,i.jsx)(e.h2,{id:"footstep-planning-for-bipedal-navigation",children:"Footstep Planning for Bipedal Navigation"}),"\n",(0,i.jsx)(e.h3,{id:"footstep-planner-integration",children:"Footstep Planner Integration"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# Example footstep planner for humanoid navigation\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import PoseStamped, Point\nfrom nav_msgs.msg import Path\nfrom visualization_msgs.msg import Marker\nimport numpy as np\n\nclass FootstepPlannerNode(Node):\n    def __init__(self):\n        super().__init__(\'footstep_planner\')\n\n        self.path_subscription = self.create_subscription(\n            Path,\n            \'global_plan\',\n            self.path_callback,\n            10\n        )\n\n        self.footstep_publisher = self.create_publisher(\n            Path,\n            \'footstep_plan\',\n            10\n        )\n\n        self.visualization_publisher = self.create_publisher(\n            Marker,\n            \'footstep_visualization\',\n            10\n        )\n\n    def path_callback(self, path_msg):\n        """Convert global path to footstep plan"""\n        footstep_plan = self.generate_footsteps(path_msg)\n        self.footstep_publisher.publish(footstep_plan)\n        self.visualize_footsteps(footstep_plan)\n\n    def generate_footsteps(self, path_msg):\n        """Generate footstep plan from global path"""\n        footsteps = Path()\n        footsteps.header = path_msg.header\n\n        # Generate footsteps along the path\n        step_size = 0.3  # meters between footsteps\n        current_pos = np.array([0.0, 0.0])\n        step_offset = 0.0  # Alternate left/right foot\n\n        for i in range(1, len(path_msg.poses)):\n            start = np.array([path_msg.poses[i-1].pose.position.x,\n                             path_msg.poses[i-1].pose.position.y])\n            end = np.array([path_msg.poses[i].pose.position.x,\n                           path_msg.poses[i].pose.position.y])\n\n            segment_length = np.linalg.norm(end - start)\n            direction = (end - start) / segment_length if segment_length > 0 else np.array([1, 0])\n\n            # Generate footsteps along this segment\n            distance = 0\n            while distance < segment_length:\n                step_pos = start + distance * direction\n                pose = PoseStamped()\n                pose.header = path_msg.header\n                pose.pose.position.x = float(step_pos[0])\n                pose.pose.position.y = float(step_pos[1])\n                pose.pose.position.z = 0.0  # Ground level\n\n                # Alternate feet\n                if step_offset == 0:\n                    pose.pose.position.y += 0.1  # Right foot\n                    step_offset = 0.1\n                else:\n                    pose.pose.position.y -= 0.2  # Left foot\n                    step_offset = 0.0\n\n                # Set orientation to match path direction\n                pose.pose.orientation.z = float(direction[1])\n                pose.pose.orientation.w = float(direction[0])\n\n                footsteps.poses.append(pose)\n                distance += step_size\n\n        return footsteps\n\n    def visualize_footsteps(self, footsteps):\n        """Visualize footsteps in RViz"""\n        marker = Marker()\n        marker.header = footsteps.header\n        marker.ns = "footsteps"\n        marker.id = 0\n        marker.type = Marker.SPHERE_LIST\n        marker.action = Marker.ADD\n        marker.scale.x = 0.05\n        marker.scale.y = 0.05\n        marker.scale.z = 0.01\n        marker.color.r = 1.0\n        marker.color.g = 0.0\n        marker.color.b = 0.0\n        marker.color.a = 1.0\n\n        for pose in footsteps.poses:\n            point = Point()\n            point.x = pose.pose.position.x\n            point.y = pose.pose.position.y\n            point.z = pose.pose.position.z\n            marker.points.append(point)\n\n        self.visualization_publisher.publish(marker)\n'})}),"\n",(0,i.jsx)(e.h2,{id:"balance-control-integration",children:"Balance Control Integration"}),"\n",(0,i.jsx)(e.h3,{id:"center-of-mass-management",children:"Center of Mass Management"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"# Example balance control for humanoid navigation\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist, PointStamped\nfrom sensor_msgs.msg import Imu\nfrom tf2_ros import TransformListener, Buffer\nimport numpy as np\n\nclass BalanceControllerNode(Node):\n    def __init__(self):\n        super().__init__('balance_controller')\n\n        self.cmd_vel_publisher = self.create_publisher(Twist, 'cmd_vel', 10)\n        self.imu_subscription = self.create_subscription(\n            Imu,\n            'imu/data',\n            self.imu_callback,\n            10\n        )\n\n        self.tf_buffer = Buffer()\n        self.tf_listener = TransformListener(self.tf_buffer, self)\n\n        # Balance control parameters\n        self.balance_threshold = 0.1  # meters\n        self.max_correction_velocity = 0.2  # m/s\n        self.balance_gains = {'p': 2.0, 'i': 0.1, 'd': 0.05}\n\n        self.imu_orientation = None\n        self.error_integral = 0.0\n        self.previous_error = 0.0\n\n        self.timer = self.create_timer(0.05, self.balance_control_loop)  # 20Hz\n\n    def imu_callback(self, msg):\n        \"\"\"Process IMU data for balance estimation\"\"\"\n        self.imu_orientation = msg.orientation\n\n    def balance_control_loop(self):\n        \"\"\"Main balance control loop\"\"\"\n        if self.imu_orientation is None:\n            return\n\n        # Calculate balance error (simplified)\n        # In reality, you'd use more sophisticated CoM estimation\n        roll, pitch, yaw = self.quaternion_to_euler(\n            self.imu_orientation.x,\n            self.imu_orientation.y,\n            self.imu_orientation.z,\n            self.imu_orientation.w\n        )\n\n        # Balance error based on pitch (forward/backward lean)\n        error = pitch\n\n        # PID control for balance correction\n        self.error_integral += error * 0.05  # dt = 0.05s\n        derivative = (error - self.previous_error) / 0.05\n\n        correction = (\n            self.balance_gains['p'] * error +\n            self.balance_gains['i'] * self.error_integral +\n            self.balance_gains['d'] * derivative\n        )\n\n        # Limit correction\n        correction = max(min(correction, self.max_correction_velocity),\n                        -self.max_correction_velocity)\n\n        # Publish velocity command to maintain balance\n        cmd_vel = Twist()\n        cmd_vel.linear.x = min(max(-correction, -0.1), 0.1)  # Forward/backward adjustment\n        cmd_vel.angular.z = 0.0  # No turning in balance mode\n\n        self.cmd_vel_publisher.publish(cmd_vel)\n        self.previous_error = error\n\n    def quaternion_to_euler(self, x, y, z, w):\n        \"\"\"Convert quaternion to Euler angles\"\"\"\n        # Roll (x-axis rotation)\n        sinr_cosp = 2 * (w * x + y * z)\n        cosr_cosp = 1 - 2 * (x * x + y * y)\n        roll = np.arctan2(sinr_cosp, cosr_cosp)\n\n        # Pitch (y-axis rotation)\n        sinp = 2 * (w * y - z * x)\n        if np.abs(sinp) >= 1:\n            pitch = np.copysign(np.pi / 2, sinp)\n        else:\n            pitch = np.arcsin(sinp)\n\n        # Yaw (z-axis rotation)\n        siny_cosp = 2 * (w * z + x * y)\n        cosy_cosp = 1 - 2 * (y * y + z * z)\n        yaw = np.arctan2(siny_cosp, cosy_cosp)\n\n        return roll, pitch, yaw\n"})}),"\n",(0,i.jsx)(e.h2,{id:"navigation-recovery-behaviors-for-humanoids",children:"Navigation Recovery Behaviors for Humanoids"}),"\n",(0,i.jsx)(e.h3,{id:"specialized-recovery-behaviors",children:"Specialized Recovery Behaviors"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# Example of humanoid-specific recovery behaviors\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Twist\nfrom builtin_interfaces.msg import Duration\n\nclass HumanoidRecoveryNode(Node):\n    def __init__(self):\n        super().__init__(\'humanoid_recovery\')\n\n        self.recovery_trigger_subscription = self.create_subscription(\n            String,\n            \'recovery_trigger\',\n            self.recovery_callback,\n            10\n        )\n\n        self.cmd_vel_publisher = self.create_publisher(Twist, \'cmd_vel\', 10)\n\n        self.recovery_behaviors = {\n            \'back_up\': self.back_up_recovery,\n            \'spin_in_place\': self.spin_recovery,\n            \'wait\': self.wait_recovery,\n            \'step_back\': self.step_back_recovery  # Humanoid-specific\n        }\n\n    def recovery_callback(self, msg):\n        """Handle recovery behavior requests"""\n        behavior = msg.data\n        if behavior in self.recovery_behaviors:\n            self.get_logger().info(f\'Executing recovery behavior: {behavior}\')\n            self.recovery_behaviors[behavior]()\n        else:\n            self.get_logger().warn(f\'Unknown recovery behavior: {behavior}\')\n\n    def step_back_recovery(self):\n        """Humanoid-specific recovery: step back carefully"""\n        self.get_logger().info(\'Executing step-back recovery\')\n\n        # Publish command to take a careful step back\n        cmd_vel = Twist()\n        cmd_vel.linear.x = -0.1  # Slow backward movement\n        cmd_vel.angular.z = 0.0\n\n        # Execute for a short duration\n        self.execute_command_for_duration(cmd_vel, 2.0)\n\n    def back_up_recovery(self):\n        """Standard backup recovery"""\n        cmd_vel = Twist()\n        cmd_vel.linear.x = -0.2\n        cmd_vel.angular.z = 0.0\n\n        self.execute_command_for_duration(cmd_vel, 1.0)\n\n    def spin_recovery(self):\n        """Spin in place recovery"""\n        cmd_vel = Twist()\n        cmd_vel.linear.x = 0.0\n        cmd_vel.angular.z = 0.5  # 0.5 rad/s rotation\n\n        self.execute_command_for_duration(cmd_vel, 3.0)\n\n    def wait_recovery(self):\n        """Wait recovery"""\n        cmd_vel = Twist()\n        cmd_vel.linear.x = 0.0\n        cmd_vel.angular.z = 0.0\n\n        self.execute_command_for_duration(cmd_vel, 5.0)\n\n    def execute_command_for_duration(self, cmd_vel, duration):\n        """Execute a command for a specific duration"""\n        start_time = self.get_clock().now()\n\n        while (self.get_clock().now() - start_time).nanoseconds < duration * 1e9:\n            self.cmd_vel_publisher.publish(cmd_vel)\n            rclpy.spin_once(self, timeout_sec=0.1)\n\n        # Stop the robot\n        stop_cmd = Twist()\n        self.cmd_vel_publisher.publish(stop_cmd)\n'})}),"\n",(0,i.jsx)(e.h2,{id:"simulation-and-testing",children:"Simulation and Testing"}),"\n",(0,i.jsx)(e.h3,{id:"gazebo-integration-for-humanoid-nav2",children:"Gazebo Integration for Humanoid Nav2"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'\x3c!-- Example Gazebo plugin for humanoid navigation simulation --\x3e\n<gazebo>\n  <plugin name="nav2_simulation_plugin" filename="libnav2_robot_plugin.so">\n    <ros>\n      <namespace>/humanoid_robot</namespace>\n      <remappings>\n        <remap from="cmd_vel" to="cmd_vel_nav"/>\n        <remap from="odom" to="odom"/>\n        <remap from="scan" to="laser_scan"/>\n        <remap from="imu" to="imu/data"/>\n      </remappings>\n    </ros>\n    <odom_frame>odom</odom_frame>\n    <base_frame>base_link</base_frame>\n    <odom_publish_frequency>20.0</odom_publish_frequency>\n    <broadcast_tf>true</broadcast_tf>\n    \x3c!-- Humanoid-specific parameters --\x3e\n    <foot_separation>0.2</foot_separation>\n    <step_height>0.05</step_height>\n    <balance_margin>0.05</balance_margin>\n  </plugin>\n</gazebo>\n'})}),"\n",(0,i.jsx)(e.h3,{id:"testing-navigation-scenarios",children:"Testing Navigation Scenarios"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"# Example navigation testing script\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import PoseStamped\nfrom action_msgs.msg import GoalStatus\nfrom nav2_msgs.action import NavigateToPose\nfrom rclpy.action import ActionClient\n\nclass NavigationTestNode(Node):\n    def __init__(self):\n        super().__init__('navigation_test')\n        self.navigation_client = ActionClient(self, NavigateToPose, 'navigate_to_pose')\n\n        # Test scenarios for humanoid navigation\n        self.test_scenarios = [\n            {'name': 'Straight line', 'goal': (2.0, 0.0, 0.0)},\n            {'name': '90 degree turn', 'goal': (2.0, 2.0, 1.57)},\n            {'name': 'Narrow passage', 'goal': (5.0, 0.0, 0.0)},\n            {'name': 'Obstacle avoidance', 'goal': (3.0, 3.0, 0.0)}\n        ]\n\n        self.test_index = 0\n        self.timer = self.create_timer(5.0, self.run_next_test)\n\n    def run_next_test(self):\n        \"\"\"Run the next navigation test\"\"\"\n        if self.test_index >= len(self.test_scenarios):\n            self.get_logger().info('All tests completed')\n            return\n\n        scenario = self.test_scenarios[self.test_index]\n        self.get_logger().info(f'Running test: {scenario[\"name\"]}')\n\n        goal_msg = NavigateToPose.Goal()\n        goal_msg.pose.header.frame_id = 'map'\n        goal_msg.pose.pose.position.x = float(scenario['goal'][0])\n        goal_msg.pose.pose.position.y = float(scenario['goal'][1])\n        goal_msg.pose.pose.orientation.z = float(scenario['goal'][2])\n        goal_msg.pose.pose.orientation.w = 1.0\n\n        self.send_goal_async(goal_msg)\n        self.test_index += 1\n\n    def send_goal_async(self, goal_msg):\n        \"\"\"Send navigation goal\"\"\"\n        self.navigation_client.wait_for_server()\n        future = self.navigation_client.send_goal_async(\n            goal_msg,\n            feedback_callback=self.feedback_callback\n        )\n        future.add_done_callback(self.goal_response_callback)\n\n    def goal_response_callback(self, future):\n        \"\"\"Handle goal response\"\"\"\n        goal_handle = future.result()\n        if not goal_handle.accepted:\n            self.get_logger().info('Goal rejected')\n            return\n\n        self.get_logger().info('Goal accepted')\n        get_result_future = goal_handle.get_result_async()\n        get_result_future.add_done_callback(self.get_result_callback)\n\n    def get_result_callback(self, future):\n        \"\"\"Handle navigation result\"\"\"\n        status = future.result().status\n        if status == GoalStatus.STATUS_SUCCEEDED:\n            self.get_logger().info('Navigation succeeded')\n        else:\n            self.get_logger().info(f'Navigation failed with status: {status}')\n\n    def feedback_callback(self, feedback_msg):\n        \"\"\"Handle navigation feedback\"\"\"\n        feedback = feedback_msg.feedback\n        self.get_logger().info(f'Current pose: ({feedback.current_pose.pose.position.x:.2f}, {feedback.current_pose.pose.position.y:.2f})')\n"})}),"\n",(0,i.jsx)(e.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,i.jsx)(e.h3,{id:"computational-efficiency-for-humanoid-navigation",children:"Computational Efficiency for Humanoid Navigation"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# Example optimization techniques for humanoid navigation\nclass OptimizedHumanoidNav:\n    def __init__(self):\n        # Pre-allocated arrays for performance\n        self.foot_positions = np.zeros((100, 2))  # Pre-allocate for 100 footsteps\n        self.trajectory_buffer = np.zeros((50, 3))  # Pre-allocate trajectory points\n        self.costmap_buffer = None\n\n        # Optimized data structures\n        self.footstep_queue = collections.deque(maxlen=50)\n        self.balance_history = collections.deque(maxlen=20)\n\n    def optimized_footstep_generation(self, path, resolution=0.1):\n        """Optimized footstep generation with pre-allocation"""\n        num_steps = int(len(path) / resolution)\n\n        # Use pre-allocated array\n        self.foot_positions.fill(0)\n\n        for i in range(min(num_steps, len(self.foot_positions))):\n            # Calculate footstep position\n            idx = int(i * resolution)\n            if idx < len(path):\n                self.foot_positions[i, 0] = path[idx].position.x\n                self.foot_positions[i, 1] = path[idx].position.y\n\n        return self.foot_positions[:num_steps]\n\n    def efficient_balance_control(self, sensor_data):\n        """Efficient balance control with deque"""\n        # Add current measurement to history\n        self.balance_history.append(sensor_data.balance_state)\n\n        # Calculate moving average efficiently\n        avg_balance = sum(self.balance_history) / len(self.balance_history)\n\n        # Simple balance correction\n        correction = self.calculate_balance_correction(avg_balance)\n        return correction\n'})}),"\n",(0,i.jsx)(e.h2,{id:"best-practices-for-humanoid-navigation",children:"Best Practices for Humanoid Navigation"}),"\n",(0,i.jsx)(e.h3,{id:"safety-considerations",children:"Safety Considerations"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Stability Margins"}),": Always maintain safety margins for balance"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Step Verification"}),": Verify each step before execution"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Fall Detection"}),": Implement robust fall detection and recovery"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Emergency Stop"}),": Quick stop capabilities for safety"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"performance-optimization-1",children:"Performance Optimization"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Resolution Matching"}),": Match costmap resolution to foot size"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Update Frequency"}),": Balance accuracy with computational load"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Predictive Planning"}),": Plan several steps ahead"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Sensor Fusion"}),": Combine multiple sensors for robust navigation"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"testing-and-validation",children:"Testing and Validation"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Simulation First"}),": Test extensively in simulation"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Gradual Complexity"}),": Start with simple scenarios"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Real-World Validation"}),": Verify on physical robot"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Edge Cases"}),": Test unusual scenarios"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"troubleshooting-common-issues",children:"Troubleshooting Common Issues"}),"\n",(0,i.jsx)(e.h3,{id:"navigation-failures",children:"Navigation Failures"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Check costmap inflation settings"}),"\n",(0,i.jsx)(e.li,{children:"Verify sensor data quality"}),"\n",(0,i.jsx)(e.li,{children:"Validate footstep planning parameters"}),"\n",(0,i.jsx)(e.li,{children:"Ensure proper localization"}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"balance-problems",children:"Balance Problems"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Tune balance controller gains"}),"\n",(0,i.jsx)(e.li,{children:"Verify IMU calibration"}),"\n",(0,i.jsx)(e.li,{children:"Check CoM estimation"}),"\n",(0,i.jsx)(e.li,{children:"Adjust step timing parameters"}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"performance-issues",children:"Performance Issues"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Optimize costmap resolution"}),"\n",(0,i.jsx)(e.li,{children:"Reduce planning frequency if possible"}),"\n",(0,i.jsx)(e.li,{children:"Check CPU/GPU utilization"}),"\n",(0,i.jsx)(e.li,{children:"Profile individual components"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"rag-summary",children:"RAG Summary"}),"\n",(0,i.jsx)(e.p,{children:"Nav2 can be adapted for bipedal humanoid navigation by addressing unique challenges like balance control, footstep planning, and motion constraints. Key modifications include specialized costmap configuration, footstep planning algorithms, balance control integration, and humanoid-specific recovery behaviors. The system requires careful tuning of parameters to ensure stable and efficient navigation while maintaining balance."}),"\n",(0,i.jsx)(e.h2,{id:"knowledge-check",children:"Knowledge Check"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsx)(e.li,{children:"What are the main challenges of bipedal navigation compared to wheeled navigation?"}),"\n",(0,i.jsx)(e.li,{children:"How do you configure Nav2 costmaps for humanoid robots?"}),"\n",(0,i.jsx)(e.li,{children:"What is the role of footstep planning in humanoid navigation?"}),"\n",(0,i.jsx)(e.li,{children:"How do you implement balance control in humanoid navigation systems?"}),"\n",(0,i.jsx)(e.li,{children:"What are the key considerations for humanoid-specific recovery behaviors?"}),"\n"]})]})}function _(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(d,{...n})}):d(n)}},8453:(n,e,o)=>{o.d(e,{R:()=>s});var a=o(6540);const i={},t=a.createContext(i);function s(n){const e=a.useContext(t);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}}}]);