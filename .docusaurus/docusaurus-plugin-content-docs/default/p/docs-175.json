{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","href":"/docs/intro/","label":"Introduction to Physical AI & Humanoid Robotics","docId":"intro/intro","unlisted":false},{"type":"category","label":"modules","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Module 1: ROS 2 Fundamentals","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/modules/module-1-ros2/nodes-topics-services","label":"ROS 2 Nodes, Topics, Services","docId":"modules/module-1-ros2/nodes-topics-services","unlisted":false},{"type":"link","href":"/docs/modules/module-1-ros2/rclpy-python-agent","label":"rclpy: Bridging Python Agents to ROS 2","docId":"modules/module-1-ros2/rclpy-python-agent","unlisted":false},{"type":"link","href":"/docs/modules/module-1-ros2/urdf-humanoid","label":"URDF Basics for Humanoid Robots","docId":"modules/module-1-ros2/urdf-humanoid","unlisted":false}],"href":"/docs/modules/module-1-ros2/"},{"type":"category","label":"Module 2: Digital Twin (Gazebo & Unity)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/modules/module-2-digital-twin/gazebo-physics","label":"Gazebo Physics: Gravity, Collisions","docId":"modules/module-2-digital-twin/gazebo-physics","unlisted":false},{"type":"link","href":"/docs/modules/module-2-digital-twin/sensor-simulation","label":"Environment & Sensor Simulation (LiDAR, Depth, IMU)","docId":"modules/module-2-digital-twin/sensor-simulation","unlisted":false},{"type":"link","href":"/docs/modules/module-2-digital-twin/unity-rendering","label":"Unity: High-Fidelity Rendering & Interaction","docId":"modules/module-2-digital-twin/unity-rendering","unlisted":false}],"href":"/docs/modules/module-2-digital-twin/"},{"type":"category","label":"Module 3: AI-Robot Brain (NVIDIA Isaac™)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/modules/module-3-ai-brain/isaac-sim","label":"Isaac Sim: Photorealistic Simulation + Synthetic Data","docId":"modules/module-3-ai-brain/isaac-sim","unlisted":false},{"type":"link","href":"/docs/modules/module-3-ai-brain/isaac-ros-pipelines","label":"Isaac ROS Pipelines: VSLAM, Navigation","docId":"modules/module-3-ai-brain/isaac-ros-pipelines","unlisted":false},{"type":"link","href":"/docs/modules/module-3-ai-brain/nav2-bipedal","label":"Nav2 for Bipedal Humanoid Movement","docId":"modules/module-3-ai-brain/nav2-bipedal","unlisted":false}],"href":"/docs/modules/module-3-ai-brain/"},{"type":"category","label":"Module 4: Vision-Language-Action (VLA)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/modules/module-4-vla/whisper-voice-action","label":"Voice-to-Action (Whisper)","docId":"modules/module-4-vla/whisper-voice-action","unlisted":false},{"type":"link","href":"/docs/modules/module-4-vla/llm-cognitive-planning","label":"Cognitive Planning (LLMs → ROS 2 actions)","docId":"modules/module-4-vla/llm-cognitive-planning","unlisted":false},{"type":"link","href":"/docs/modules/module-4-vla/autonomous-humanoid","label":"Capstone: Autonomous Humanoid Pipeline","docId":"modules/module-4-vla/autonomous-humanoid","unlisted":false}],"href":"/docs/modules/module-4-vla/"}]}]},"docs":{"intro/intro":{"id":"intro/intro","title":"Introduction to Physical AI & Humanoid Robotics","description":"Welcome to the comprehensive educational book on Physical AI & Humanoid Robotics. This book covers the complete end-to-end robotics pipeline from middleware to perception to action, with a focus on modern approaches using ROS 2, simulation environments, AI perception systems, and Vision-Language-Action (VLA) systems.","sidebar":"tutorialSidebar"},"modules/module-1-ros2/index":{"id":"modules/module-1-ros2/index","title":"Module 1: ROS 2 Fundamentals","description":"Welcome to Module 1 of the Physical AI & Humanoid Robotics book. This module covers the foundational concepts of ROS 2, which serves as the robotic nervous system for humanoid robots.","sidebar":"tutorialSidebar"},"modules/module-1-ros2/nodes-topics-services":{"id":"modules/module-1-ros2/nodes-topics-services","title":"ROS 2 Nodes, Topics, Services","description":"Introduction","sidebar":"tutorialSidebar"},"modules/module-1-ros2/rclpy-python-agent":{"id":"modules/module-1-ros2/rclpy-python-agent","title":"rclpy: Bridging Python Agents to ROS 2","description":"Introduction","sidebar":"tutorialSidebar"},"modules/module-1-ros2/urdf-humanoid":{"id":"modules/module-1-ros2/urdf-humanoid","title":"URDF Basics for Humanoid Robots","description":"Introduction","sidebar":"tutorialSidebar"},"modules/module-2-digital-twin/gazebo-physics":{"id":"modules/module-2-digital-twin/gazebo-physics","title":"Gazebo Physics: Gravity, Collisions","description":"Introduction","sidebar":"tutorialSidebar"},"modules/module-2-digital-twin/index":{"id":"modules/module-2-digital-twin/index","title":"Module 2: Digital Twin (Gazebo & Unity)","description":"Welcome to Module 2 of the Physical AI & Humanoid Robotics book. This module explores digital twin concepts using simulation environments, focusing on physics simulation, sensor modeling, and high-fidelity rendering.","sidebar":"tutorialSidebar"},"modules/module-2-digital-twin/sensor-simulation":{"id":"modules/module-2-digital-twin/sensor-simulation","title":"Environment & Sensor Simulation (LiDAR, Depth, IMU)","description":"Introduction","sidebar":"tutorialSidebar"},"modules/module-2-digital-twin/unity-rendering":{"id":"modules/module-2-digital-twin/unity-rendering","title":"Unity: High-Fidelity Rendering & Interaction","description":"Introduction","sidebar":"tutorialSidebar"},"modules/module-3-ai-brain/index":{"id":"modules/module-3-ai-brain/index","title":"Module 3: AI-Robot Brain (NVIDIA Isaac™)","description":"Welcome to Module 3 of the Physical AI & Humanoid Robotics book. This module focuses on AI-powered perception and navigation systems using NVIDIA Isaac technologies.","sidebar":"tutorialSidebar"},"modules/module-3-ai-brain/isaac-ros-pipelines":{"id":"modules/module-3-ai-brain/isaac-ros-pipelines","title":"Isaac ROS Pipelines: VSLAM, Navigation","description":"Introduction","sidebar":"tutorialSidebar"},"modules/module-3-ai-brain/isaac-sim":{"id":"modules/module-3-ai-brain/isaac-sim","title":"Isaac Sim: Photorealistic Simulation + Synthetic Data","description":"Introduction","sidebar":"tutorialSidebar"},"modules/module-3-ai-brain/nav2-bipedal":{"id":"modules/module-3-ai-brain/nav2-bipedal","title":"Nav2 for Bipedal Humanoid Movement","description":"Introduction","sidebar":"tutorialSidebar"},"modules/module-4-vla/autonomous-humanoid":{"id":"modules/module-4-vla/autonomous-humanoid","title":"Capstone: Autonomous Humanoid Pipeline","description":"Introduction","sidebar":"tutorialSidebar"},"modules/module-4-vla/index":{"id":"modules/module-4-vla/index","title":"Module 4: Vision-Language-Action (VLA)","description":"Welcome to Module 4 of the Physical AI & Humanoid Robotics book. This module focuses on Vision-Language-Action systems that enable humanoid robots to understand and respond to human commands through voice and visual input.","sidebar":"tutorialSidebar"},"modules/module-4-vla/llm-cognitive-planning":{"id":"modules/module-4-vla/llm-cognitive-planning","title":"Cognitive Planning (LLMs → ROS 2 actions)","description":"Introduction","sidebar":"tutorialSidebar"},"modules/module-4-vla/whisper-voice-action":{"id":"modules/module-4-vla/whisper-voice-action","title":"Voice-to-Action (Whisper)","description":"Introduction","sidebar":"tutorialSidebar"}}}}